# --- Jour 2 : NLP Analyzer avec HuggingFace ---
from transformers import pipeline
from typing import Dict, Any
from dotenv import load_dotenv

load_dotenv()

# Seuils pour les labels Green/Yellow/Red bas√©s sur la confiance du mod√®le
CONFIDENCE_THRESHOLDS = {
    "high": 0.85,    # Score > 0.85 = tr√®s confiant
    "medium": 0.65   # Score entre 0.65-0.85 = moyennement confiant
}

MODEL = "jy46604790/Fake-News-Bert-Detect"
clf = pipeline("text-classification", model=MODEL, tokenizer=MODEL)


def interpret_model_result(result: list) -> Dict[str, Any]:
    """
    Interpr√©ter le r√©sultat du mod√®le HuggingFace
    LABEL_0: Fake news, LABEL_1: Real news
    Le score repr√©sente la CONFIANCE du mod√®le en sa pr√©diction (0-1)
    Format attendu: [{'label': 'LABEL_1', 'score': 0.9994995594024658}]
    """
    if not result or len(result) == 0:
        return {
            "score": 0.5,
            "label": "Yellow",
            "explanation": "Erreur d'analyse",
            "confidence": "low"
        }

    prediction = result[0]
    model_label = prediction['label']
    model_confidence = prediction['score']  # Confiance du mod√®le (0-1)

    # D√©terminer la pr√©diction du mod√®le
    is_fake_prediction = (model_label == "LABEL_0")
    is_real_prediction = (model_label == "LABEL_1")

    # Calculer le score final pour notre syst√®me (0 = fake, 1 = real)
    if is_real_prediction:
        # Le mod√®le pense que c'est real avec X% de confiance
        final_score = 0.5 + (model_confidence - 0.5)  # Scale de 0.5 √† 1
    else:  # is_fake_prediction
        # Le mod√®le pense que c'est fake avec X% de confiance
        final_score = 0.5 - (model_confidence - 0.5)  # Scale de 0.5 √† 0

    # S'assurer que le score reste entre 0 et 1
    final_score = max(0.0, min(1.0, final_score))

    # D√©terminer le niveau de confiance global
    if model_confidence >= CONFIDENCE_THRESHOLDS["high"]:
        confidence = "high"
    elif model_confidence >= CONFIDENCE_THRESHOLDS["medium"]:
        confidence = "medium"
    else:
        confidence = "low"

    # D√©terminer le label et l'explication bas√©s sur le score final et la confiance
    if final_score >= 0.75:
        label = "Green"
        if confidence == "high":
            explanation = f"Source tr√®s fiable (confiance: {model_confidence:.0%})"
        else:
            explanation = f"Source probablement fiable (confiance: {model_confidence:.0%})"
    elif final_score >= 0.4:
        label = "Yellow"
        if confidence == "low":
            explanation = f"R√©sultat incertain, confiance faible ({model_confidence:.0%})"
        else:
            explanation = f"Source √† v√©rifier (confiance: {model_confidence:.0%})"
    else:
        label = "Red"
        if confidence == "high":
            explanation = f"Contenu tr√®s probablement faux (confiance: {model_confidence:.0%})"
        else:
            explanation = f"Source douteuse (confiance: {model_confidence:.0%})"

    return {
        "score": round(final_score, 2),
        "label": label,
        "explanation": explanation,
        "confidence": confidence,
        "model_details": {
            "model_label": model_label,
            "model_confidence": round(model_confidence, 3),
            "prediction": "fake_news" if is_fake_prediction else "real_news"
        }
    }


async def analyze_with_huggingface(text: str) -> Dict[str, Any]:
    """Analyser le texte avec le mod√®le HuggingFace (fake news detection)"""
    try:
        # Analyse avec le mod√®le local
        result = clf(text)
        print(text)
        print(f"üîç R√©sultat mod√®le: {result}")

        # Interpr√©ter le r√©sultat
        interpreted_result = interpret_model_result(result)

        return {
            **interpreted_result,
            "api_available": True
        }

    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur mod√®le: {e}")
        return {
            "score": 0.5,
            "label": "Yellow",
            "explanation": "Erreur lors de l'analyse IA",
            "confidence": "low",
            "api_available": False
        }


async def analyze_text(text: str) -> Dict[str, Any]:
    """
    Fonction principale d'analyse de texte
    Utilise le mod√®le HuggingFace pour d√©tecter les fake news
    """
    # V√©rification de base
    if not text or len(text.strip()) < 10:
        return {
            "score": 0.5,
            "label": "Yellow",
            "explanation": "Texte trop court pour une analyse fiable",
            "confidence": "low",
            "model_details": None
        }

    # Analyse avec le mod√®le IA
    result = await analyze_with_huggingface(text)

    return result
